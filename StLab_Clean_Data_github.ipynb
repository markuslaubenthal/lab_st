{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StLab_Clean_Data_github.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QhqkVHHXe9m",
        "outputId": "caa8b509-9af5-4d7f-a1b8-23589d7262fe"
      },
      "source": [
        "!wget \"https://storage.googleapis.com/laubenthal_spatiolab/spatio_merged_data_iss.zip\" --no-verbose\n",
        "!unzip spatio_merged_data_iss.zip\n",
        "!rm spatio_merged_data_iss.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-18 15:25:42 URL:https://storage.googleapis.com/laubenthal_spatiolab/spatio_merged_data_iss.zip [37282886/37282886] -> \"spatio_merged_data_iss.zip\" [1]\n",
            "Archive:  spatio_merged_data_iss.zip\n",
            "   creating: input/\n",
            "  inflating: input/.DS_Store         \n",
            "  inflating: __MACOSX/input/._.DS_Store  \n",
            "  inflating: input/grid_ML.geojson   \n",
            "  inflating: __MACOSX/input/._grid_ML.geojson  \n",
            "  inflating: input/internet_ML.csv   \n",
            "  inflating: __MACOSX/input/._internet_ML.csv  \n",
            "  inflating: input/satelite.png      \n",
            "  inflating: __MACOSX/input/._satelite.png  \n",
            "  inflating: input/weather.csv       \n",
            "  inflating: __MACOSX/input/._weather.csv  \n",
            "  inflating: input/social_pulse_ML.csv  \n",
            "  inflating: __MACOSX/input/._social_pulse_ML.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZ1nZzGkr5Jg",
        "outputId": "f37c6ba7-f892-4de3-8d71-151b11ccdc16"
      },
      "source": [
        "!rm -rf functions\n",
        "!git clone https://github.com/markuslaubenthal/lab_st.git functions"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'functions'...\n",
            "remote: Enumerating objects: 104, done.\u001b[K\n",
            "remote: Counting objects: 100% (104/104), done.\u001b[K\n",
            "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
            "remote: Total 104 (delta 45), reused 76 (delta 24), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (104/104), 149.41 KiB | 4.04 MiB/s, done.\n",
            "Resolving deltas: 100% (45/45), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPc1Iy8WXivI"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, activations\n",
        "from keras import backend as K\n",
        "from keras.engine.topology import Layer\n",
        "import tensorflow as tf"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0WgyYa4Go-6"
      },
      "source": [
        "from functions.preprocessing.DataImport import load_and_scale_internet, load_and_scale_satelite, load_and_scale_social, load_and_scale_weather, create_space_invariant\n",
        "from functions.preprocessing.DataGeneration import generate_dataset, generate_label, getFileHandler, get_datasets_from_file"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYvtwt9ReLDR"
      },
      "source": [
        "f = getFileHandler(\"training_data.h5\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJOdgb9tJS-z"
      },
      "source": [
        "internet, internet_origin, internet_min, internet_max = load_and_scale_internet('input/internet_ML.csv', f)\n",
        "satelite = load_and_scale_satelite('input/satelite.png', f)\n",
        "social = load_and_scale_social('input/social_pulse_ML.csv', f)\n",
        "weather = load_and_scale_weather('input/weather.csv', f)\n",
        "hour, weekday, holiday = create_space_invariant(f)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHXT0DBtM19h"
      },
      "source": [
        "x_closeness = generate_dataset(internet, [1,2,3], 168, f, \"closeness\")\n",
        "x_period = generate_dataset(internet, [7,14,21,168], 168, f, \"period\")\n",
        "y = generate_label(internet, 168, f)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzWh4D_2x4s3"
      },
      "source": [
        "from functions.preprocessing.TestTrainSplit import seven_days_train_test_split\n",
        "\n",
        "x_closeness_train, x_closeness_test = seven_days_train_test_split(x_closeness, 168)\n",
        "x_period_train, x_period_test = seven_days_train_test_split(x_period, 168)\n",
        "y_train, y_test = seven_days_train_test_split(y, 168)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRZNJlWHMSNs"
      },
      "source": [
        "from functions.model.SplitDenseNetFactory import SplitDenseNetFactory\n",
        "from keras.optimizers import SGD, Adam\n",
        "dn = SplitDenseNetFactory()\n",
        "model = dn.Model(4,3)\n",
        "lr = 0.01\n",
        "epochs = 2\n",
        "model.compile(optimizer=Adam(lr=lr, decay= lr/float(epochs)),\n",
        "              loss='mse',\n",
        "              metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
        "              )\n",
        "model.fit([x_closeness_train, x_period_train], y_train, epochs=32)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYRgzBMitO7T"
      },
      "source": [
        "# something like\n",
        "# pred = model.predict([x_closeness,x_period])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNJicQCHMRzA"
      },
      "source": [
        "# takes prediction pred for the entire sequence\n",
        "pred = pred.reshape((pred.shape[0],10000)).T\n",
        "pred = pred * (internet_max - internet_min)[:,np.newaxis] + internet_min[:,np.newaxis]\n",
        "pred = np.power(np.full(pred.shape, 10), pred)\n",
        "base = internet_origin[:,168:]\n",
        "print('all: ', np.sqrt(((pred-base)**2).mean()))\n",
        "print('test: ', np.sqrt(((pred[:,:-168]-base[:,:-168])**2).mean()))\n",
        "print('val: ', np.sqrt(((pred[:,-168:]-base[:,-168:])**2).mean()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAHZg0OtmaQ1"
      },
      "source": [
        "# reference plot\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(range(400), base[2878,100:500], label='base')\n",
        "plt.plot(range(400), pred[2878,100:500], label='pred')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}