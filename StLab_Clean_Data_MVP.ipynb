{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StLab_Clean_Data_MVP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QhqkVHHXe9m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb487639-f6d1-4782-c116-5be6d8ab2005"
      },
      "source": [
        "!wget \"https://storage.googleapis.com/laubenthal_spatiolab/spatio_merged_data_iss.zip\" --no-verbose\n",
        "!unzip spatio_merged_data_iss.zip\n",
        "!rm spatio_merged_data_iss.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-17 00:02:19 URL:https://storage.googleapis.com/laubenthal_spatiolab/spatio_merged_data_iss.zip [37039712/37039712] -> \"spatio_merged_data_iss.zip\" [1]\n",
            "Archive:  spatio_merged_data_iss.zip\n",
            "   creating: input/\n",
            "  inflating: input/.DS_Store         \n",
            "  inflating: __MACOSX/input/._.DS_Store  \n",
            "  inflating: input/grid_ML.geojson   \n",
            "  inflating: __MACOSX/input/._grid_ML.geojson  \n",
            "  inflating: input/satelite.png      \n",
            "  inflating: __MACOSX/input/._satelite.png  \n",
            "  inflating: input/weather.csv       \n",
            "  inflating: __MACOSX/input/._weather.csv  \n",
            "  inflating: input/social_pulse_ML.csv  \n",
            "  inflating: __MACOSX/input/._social_pulse_ML.csv  \n",
            "  inflating: input/f_internet_ML.csv  \n",
            "  inflating: __MACOSX/input/._f_internet_ML.csv  \n",
            "Cloning into 'functions'...\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 15 (delta 1), reused 15 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (15/15), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZ1nZzGkr5Jg",
        "outputId": "e748a1de-4728-4530-be3f-e1e37fa56dfe"
      },
      "source": [
        "!rm -rf functions\n",
        "!git clone https://github.com/markuslaubenthal/lab_st.git functions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'functions'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 35 (delta 6), reused 33 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (35/35), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPc1Iy8WXivI"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, activations\n",
        "from keras import backend as K\n",
        "from keras.engine.topology import Layer\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYvtwt9ReLDR"
      },
      "source": [
        "internet_origin = pd.read_csv('input/f_internet_ML.csv' , index_col='index')\n",
        "internet_origin = internet_origin.to_numpy()\n",
        "internet = np.log10(internet_origin + 1)\n",
        "internet_max = internet.max(axis=1)\n",
        "internet_min = internet.min(axis=1)\n",
        "internet = (internet - internet_min[:,np.newaxis]) / (internet_max - internet_min)[:,np.newaxis]\n",
        "internet = internet.T.reshape((1488,100,100))\n",
        "satelite = cv2.imread('input/satelite.png')\n",
        "satelite = (satelite - satelite.min()) / (satelite.max() - satelite.min())\n",
        "satelite = np.flip(satelite, axis=0)\n",
        "hour = np.zeros((24,100,100,24))\n",
        "for i in range(24):\n",
        "  hour[i,:,:,i] = 1\n",
        "weekday = np.zeros((7,100,100,7))\n",
        "for i in range(7):\n",
        "  weekday[i,:,:,i] = 1\n",
        "holidays = np.zeros((1488,100,100))\n",
        "for i in range(1488):\n",
        "  day = i // 24\n",
        "  if day % 7 in [1,2]:\n",
        "    holidays[i] = 1\n",
        "  elif day in [0,54,56,61,62]:\n",
        "    holidays[i] = 1\n",
        "social = pd.read_csv('input/social_pulse_ML.csv', index_col=0)\n",
        "social = social.to_numpy()\n",
        "social = (social - social.min(axis=1)[:,np.newaxis]) / (social.max(axis=1) - social.min(axis=1) + 1)[:,np.newaxis]\n",
        "social = social.T.reshape((1488,100,100))\n",
        "weather = pd.read_csv('input/weather.csv', index_col=0)\n",
        "weather = weather.to_numpy()\n",
        "weather = (weather - weather.min(axis=1)[:,np.newaxis]) / (weather.max(axis=1) - weather.min(axis=1) + 1)[:,np.newaxis]\n",
        "weather = weather.T.reshape((1488,100,100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHXT0DBtM19h"
      },
      "source": [
        "from functions.preprocessing.DataGeneration import generate_dataset, generate_label, getFileHandler, get_datasets_from_file\n",
        "f = getFileHandler(\"training_data.h5\")\n",
        "x_closeness = generate_dataset(internet, [1,2,3], 168, f, \"closeness\")\n",
        "x_period = generate_dataset(internet, [7,14,21,168], 168, f, \"period\")\n",
        "y = generate_label(internet, 168, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzWh4D_2x4s3"
      },
      "source": [
        "from functions.preprocessing.TestTrainSplit import seven_days_train_test_split\n",
        "\n",
        "x_closeness_train, x_closeness_test = seven_days_train_test_split(x_closeness, 168)\n",
        "x_period_train, x_period_test = seven_days_train_test_split(x_period, 168)\n",
        "y_train, y_test = seven_days_train_test_split(y, 168)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRZNJlWHMSNs"
      },
      "source": [
        "from functions.model.SplitDenseNetFactory import SplitDenseNetFactory\n",
        "from keras.optimizers import SGD, Adam\n",
        "dn = SplitDenseNetFactory()\n",
        "model = dn.Model(4,3)\n",
        "lr = 0.01\n",
        "epochs = 20\n",
        "model.compile(optimizer=Adam(lr=lr, decay= lr/float(epochs)),\n",
        "              loss='mse',\n",
        "              metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
        "              )\n",
        "model.fit([x_closeness_train, x_period_train], y_train, epochs=32)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYRgzBMitO7T"
      },
      "source": [
        "pred = model.predict(combined[:-1,:,:,:])\n",
        "pred = pred.reshape((pred.shape[0],10000)).T\n",
        "pred = pred * (internet_max - internet_min)[:,np.newaxis] + internet_min[:,np.newaxis]\n",
        "pred = np.power(np.full(pred.shape, 10), pred)\n",
        "base = internet_origin[:,1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNJicQCHMRzA"
      },
      "source": [
        "print('all: ', np.sqrt(((pred-base)**2).mean()))\n",
        "print('test: ', np.sqrt(((pred[:,:-168]-base[:,:-168])**2).mean()))\n",
        "print('val: ', np.sqrt(((pred[:,-168:]-base[:,-168:])**2).mean()))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}